import java.util.logging.FileHandler
import java.util.logging.SimpleFormatter
import java.util.logging.LogManager
import jenkins.model.Jenkins


pipeline {
    agent { docker { image 'localhost:5000/dtr/tensorflow/tensorflow:2.2.0-gpu' } }
    //agent { local { image 'tensorflow/tensorflow:2.2.0-gpu' } }
    environment {
        SLACK_WEBHOOK = 'https://hooks.slack.com/services/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'
        REGISTRY_PROD = 'registryupstrideprod.azurecr.io'
        BUILD_TAG = "upstride-python"
    }
    stages {
        stage('setup') {
            steps {
                script {
                    env.SLACK_HEADER = '[INFO] \n- push on branch <'+env.GIT_BRANCH+'>\n'+'- author <'+env.GIT_COMMITTER_NAME+'>\n'+'- email <'+env.GIT_COMMITTER_EMAIL+'>'
                    env.SLACK_MESSAGE = ''
                    env.BUILD_VERSION = sh('cat version')
                }
                setLogger()
                //publish("123", "recorded", "push on branch $GIT_BRANCH")
                aggregate("[INFO] Starting the pipeline")
            }
        }
        stage('smoke tests') {
            options {
                timeout(time: 30, unit: "SECONDS")
            }
            steps {
                script {
                    shell("""python3 test.py""")
/*                     tests = ['test.py', 'test_tf.py', 'test_type1.py','test_type2.py', 'test_type3.py']
                    for (int i = 0; i < tests.size(); i++) {
                        shell("""python3 ${tests[i]}""")
                    } */
                }
            }
        }
        stage('promote image to prod') {
            steps {
                script {
                    docker.withRegistry('${env.REGISTRY_PROD}','registry-prod'){
                        shell("""docker build -f Dockerfile -t ${env.REGISTRY_PROD}/upstride:${env.BUILD_ID} .""")
                        shell("""docker push ${REGISTRY_PROD}/upstride:${BUILD_TAG}-${BUILD_VERSION}""")
                    }
                }
            }
        }
        stage('exit') {
            steps {
                script {
                    //publish('completed','OK')
                    slack("[INFO] pipeline SUCCESS")
                }
            }
        }
    }
}

// Log into a file
def setLogger(){
    def RunLogger = LogManager.getLogManager().getLogger("global")
    def logsDir = new File(Jenkins.instance.rootDir, "logs")
    if(!logsDir.exists()){logsDir.mkdirs()}
    env.LOGFILE = logsDir.absolutePath+'/default.log'
    FileHandler handler = new FileHandler("${env.LOGFILE}", 1024 * 1024, 10, true);
    handler.setFormatter(new SimpleFormatter());
    RunLogger.addHandler(handler)
}

import groovy.json.JsonOutput;

class Event {
    def event
    def id
    def service
    def status
    def infos
}

def publish(String id, String status, String infos){
    Event evt = new Event('event':'ci', 'id':id, 'service':'bitbucket', 'status':status, 'infos':infos)
    def message = JsonOutput.toJson(evt)
    sh"""
        gcloud pubsub topics publish notifications-prod --message ${message}
    """
}

def slack(String body){
    aggregate(body)
    DATA = '\'{"text":"'+env.SLACK_HEADER+'\n'+env.SLACK_MESSAGE+'"}\''
    echo $DATA
/*     sh """
    curl -X POST -H 'Content-type: application/json' --data ${DATA} --url $SLACK_WEBHOOK
    """ */
}

def aggregate(String body){
    env.SLACK_MESSAGE = env.SLACK_MESSAGE+'\n'+body.toString()
}

def readLogs(){
    try {
        def logs = readFile(env.LOGFILE)
        return logs
    }
    catch(e){
        def logs = "-- no logs --"
        return logs
    }
}

def shell(String command){
    try {
        def output = sh(returnStatus: true, script: "${command} >${LOGFILE} 2>&1")
        if (output != 0){throw new Exception("Pipeline failed\n- command:: "+command)}
        else { return output }
    }
    catch (error){
        slack("[ERROR] "+error.getMessage()+"\n- logs: ${BUILD_URL}console")
        throw error
    }
}